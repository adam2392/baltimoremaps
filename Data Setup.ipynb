{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Setup For Maps\n",
    "\n",
    "By: Adam Li\n",
    "\n",
    "Following tutorials on D3.js, I want to create maps of different cities in the USA for data visualization. To get the geodata of any city, I am using the US package: https://pypi.python.org/pypi/us, which provides detailed information about:\n",
    "* all US states and territories\n",
    "* postal abbreviations\n",
    "* Associated Press style abbreviations\n",
    "* FIPS codes\n",
    "* capitals\n",
    "* years of statehood\n",
    "* time zones\n",
    "* phonetic state name lookup\n",
    "* is contiguous or continental\n",
    "* URLs to shapefiles for state, census, congressional districts, counties, and census tracts\n",
    "\n",
    "## Methods:\n",
    "1. GET SHAPE GEO DATA: First we gather shape data from the TIGER site. This requires us to initialize the full tiger url, state code, county lists. Then we unzip the file and store it locally. Then we gather water data from the TIGER site. \n",
    "2. CREATE GEO DATA JSON: With the shape and water data, we create a geo_data.json file that can reproduce the geo map of the location we are interested in.\n",
    "3. CENSUS TRACT information: to populate the geojson areas with some sort of data\n",
    "4. CREATE CENSUS DATA CSV: using dataframes, convert to csv easily\n",
    "\n",
    "### References:\n",
    "- Census API: https://github.com/sunlightlabs/census\n",
    "- FIPS Explanation: https://www.policymap.com/blog/2012/08/tips-on-fips-a-quick-guide-to-geographic-place-codes-part-iii/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "from census import Census\n",
    "from us import states\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN FUNCTIONS: \n",
    "- build the fips code for a blockgroup\n",
    "- build fips code for tracts\n",
    "- converting census blockgroup to a panda dataframe\n",
    "- check if a directory exists and if not create it\n",
    "- convert census blockgroup to dataframe\n",
    "- convert census tract to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_bg_fips(record):\n",
    "    fips_code = record['state'] + record['county'] + record['tract'] + record['block group']\n",
    "    return str(fips_code)\n",
    "\n",
    "def build_tract_fips(record):\n",
    "    fips_code = record['state'] + record['county'] + record['tract']\n",
    "    return str(fips_code)\n",
    "\n",
    "def census_to_dataframe(var_list, state_code, county_codes):\n",
    "    fips_codes = []\n",
    "    all_records = []\n",
    "    \n",
    "    for county in county_codes:        \n",
    "        census_data = c.acs.get(var_list, {'for': 'block group:*', 'in': 'state:{0} county:{1}'.format(state_code, county)})\n",
    "        \n",
    "        for idx, record in enumerate(census_data):\n",
    "            # Build fips codes\n",
    "            fips_code = build_bg_fips(record)\n",
    "            census_data[idx][\"fips\"] = fips_code\n",
    "\n",
    "            # Eliminate original code components\n",
    "            key_list = ['state', 'county', 'tract', 'block group']\n",
    "            for key in key_list:\n",
    "                if key in census_data[idx]: \n",
    "                    del census_data[idx][key]\n",
    "        \n",
    "        all_records.extend(census_data)\n",
    "        \n",
    "    census_df = pd.DataFrame(all_records)\n",
    "    census_df = census_df.set_index(\"fips\")\n",
    "                \n",
    "    return census_df\n",
    "\n",
    "def checkDirExist(filepath):\n",
    "    if not os.path.exists(filepath):\n",
    "        os.makedirs(filepath)\n",
    "        \n",
    "def census_bg_to_dataframe(var_list, state_code, county_codes):\n",
    "    fips_codes = []\n",
    "    all_records = []\n",
    "    \n",
    "    for county in county_codes:        \n",
    "        census_data = c.acs.get(var_list, {'for': 'tract:*', 'in': 'state:{0}'.format(state_code)})\n",
    "        \n",
    "        for idx, record in enumerate(census_data):\n",
    "            # Build fips codes\n",
    "            fips_code = build_bg_fips(record)\n",
    "            census_data[idx][\"fips\"] = fips_code\n",
    "\n",
    "            # Eliminate original code components\n",
    "            key_list = ['state', 'county', 'tract', 'block group']\n",
    "            for key in key_list:\n",
    "                if key in census_data[idx]: \n",
    "                    del census_data[idx][key]\n",
    "        \n",
    "        all_records.extend(census_data)\n",
    "        \n",
    "    census_df = pd.DataFrame(all_records)\n",
    "    census_df = census_df.set_index(\"fips\")\n",
    "                \n",
    "    return census_df\n",
    "\n",
    "def census_tracts_to_dataframe(var_list, state_codes):\n",
    "    fips_codes = []\n",
    "    all_records = []\n",
    "    \n",
    "    for state_id in state_codes:\n",
    "        census_data = c.acs.get(var_list, {'for': 'tract:*', 'in': 'state:{0}'.format(state_id)})\n",
    "\n",
    "        for idx, record in enumerate(census_data):\n",
    "\n",
    "            # Build fips codes\n",
    "            fips_code = build_tract_fips(record)\n",
    "            census_data[idx][\"fips\"] = fips_code\n",
    "\n",
    "            # Eliminate original code components\n",
    "            key_list = ['state', 'county', 'tract']\n",
    "            for key in key_list:\n",
    "                if key in census_data[idx]: \n",
    "                    del census_data[idx][key]\n",
    "        \n",
    "        all_records.extend(census_data)\n",
    "      \n",
    "    census_df = pd.DataFrame(all_records)\n",
    "    census_df = census_df.set_index(\"fips\")\n",
    "                \n",
    "    return census_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize CENSUS API and URLs For Online GEO Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CENSUS API Stuff\n",
    "CENSUS_API = 'fe55211c8b3f0350fcb040c07321a129a3d6e266' # Your key here\n",
    "c = Census(CENSUS_API) # Initialize census class with API key\n",
    "\n",
    "# TIGER Stuff\n",
    "TIGER_BASE_URL = 'http://www2.census.gov/geo/tiger/TIGER2013/'\n",
    "TIGER_TRACT_DIR = 'TRACT/'\n",
    "TIGER_BLOCKGROUP_DIR = 'BG/'\n",
    "TIGER_WATER_DIR = 'AREAWATER/'\n",
    "\n",
    "# LOCAL DATA DIR FOR STORING THE DATA FROM CENSUS.GOV\n",
    "LOCAL_DATA_DIR = './data/'\n",
    "GEO_SUB_DIR = 'geo/'\n",
    "\n",
    "# FILE ENDINGS FOR FINAL DATA TO BE SAVED\n",
    "ATTR_FILE_END = '_census_data.csv'\n",
    "GEO_FILE_END = '_geo_data.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Settings for Which states, counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Specify state and county to download (select one)\n",
    "loc_name, state_codes, county_codes = \"balt_city\", [states.MD.fips], list([510]) # Baltimore\n",
    "# Specify state and county to download (select one)\n",
    "loc_name, state_codes, county_codes = 'maryland', states.MD.fips, None\n",
    "# loc_name, state_codes, county_codes = 'delmarva', [states.MD.fips, states.DE.fips, states.VA.fips], None\n",
    "# loc_name, state_codes, county_codes = 'california', states.CA.fips, None\n",
    "loc_name, state_code, county_codes = \"balt_city\", states.MD.fips, list([510]) # Baltimore\n",
    "\n",
    "# Create county list (string representation of county IDs)\n",
    "county_list = [\"{:03d}\".format(county_id) for county_id in county_codes]\n",
    "\n",
    "# Generate codes for census variables of interest\n",
    "var_ids = [\"B19001_0{:02d}E\".format(x) for x in range(2, 18)] # Household income over 12 months\n",
    "\n",
    "# GET FILE BY STATE_CODE\n",
    "tiger_shape_file = 'tl_2013_{0}_bg.shp'.format(state_code)\n",
    "\n",
    "attr_outfile = LOCAL_DATA_DIR + loc_name + ATTR_FILE_END\n",
    "geo_outfile = LOCAL_DATA_DIR + loc_name + GEO_FILE_END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maryland state code is:  24\n",
      "['510']\n",
      "['B19001_002E', 'B19001_003E', 'B19001_004E', 'B19001_005E', 'B19001_006E', 'B19001_007E', 'B19001_008E', 'B19001_009E', 'B19001_010E', 'B19001_011E', 'B19001_012E', 'B19001_013E', 'B19001_014E', 'B19001_015E', 'B19001_016E', 'B19001_017E']\n",
      "tl_2013_2_bg.zip\n",
      "tl_2013_24_bg.shp\n",
      "balt_city\n"
     ]
    }
   ],
   "source": [
    "print \"Maryland state code is: \", state_code\n",
    "print county_list\n",
    "print var_ids\n",
    "print tiger_zip_file\n",
    "print tiger_shape_file\n",
    "print loc_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get TIGER data (shape data) From TIGER\n",
    "\n",
    "### get data by state at the blockgroup level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On state_code:  24\n",
      "http://www2.census.gov/geo/tiger/TIGER2013/BG/tl_2013_24_bg.zip\n",
      "Got files, copying to disk...\n"
     ]
    }
   ],
   "source": [
    "for state_id in state_codes:\n",
    "    tiger_zip_file = 'tl_2013_{0}_bg.zip'.format(state_id)\n",
    "\n",
    "    FULL_TIGER_URL = TIGER_BASE_URL + TIGER_BLOCKGROUP_DIR + tiger_zip_file\n",
    "    print \"On state_code: \", state_id\n",
    "    print FULL_TIGER_URL\n",
    "\n",
    "    # Check if file is in directory, else download it\n",
    "    if os.path.isfile(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_zip_file):\n",
    "        print \"Already had the file.  Great.\", tiger_zip_file\n",
    "    else:\n",
    "        r = requests.get(FULL_TIGER_URL)\n",
    "\n",
    "        if r.status_code == requests.codes.ok:\n",
    "            print \"Got files, copying to disk...\"\n",
    "            checkDirExist(LOCAL_DATA_DIR + GEO_SUB_DIR)\n",
    "            with open(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_zip_file, 'wb') as f:\n",
    "                f.write(r.content)\n",
    "        else:\n",
    "            print \"Error with getting the data. Status code: \".format(r.status_code)\n",
    "\n",
    "        # Unzip file, extract contents\n",
    "        zfile = zipfile.ZipFile(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_zip_file)\n",
    "        zfile.extractall(LOCAL_DATA_DIR + GEO_SUB_DIR)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GeoPD from:  tl_2013_24_tract.shp\n",
      "The shape of the new dataframe is:  (200, 13)\n"
     ]
    }
   ],
   "source": [
    "state_shapes = [] # list of geodataframes\n",
    "for idx, state_id in enumerate(state_codes):\n",
    "    tiger_shape_file = 'tl_2013_{0}_tract.shp'.format(state_id)\n",
    "    print \"Loading GeoPD from: \", tiger_shape_file\n",
    "\n",
    "    # Load to GeoDataFrame\n",
    "    state_shape = gpd.GeoDataFrame.from_file(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_shape_file)\n",
    "    # Only keep counties that we are interested in\n",
    "    if county_list is not None:\n",
    "        print \"Only keeping counties in: \", county_list\n",
    "        state_shape = state_shape[state_shape[\"COUNTYFP\"].isin(county_list)]\n",
    "    \n",
    "    state_shapes.append(state_shape)\n",
    "       \n",
    "# concatenate the dataframes from the tract level\n",
    "shapes = gpd.GeoDataFrame( pd.concat(state_shapes, ignore_index=True) )\n",
    "\n",
    "print \"The shape of the new dataframe is: \", shapes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET TIGER (water data) from Site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got the file! Copying to disk.\n"
     ]
    }
   ],
   "source": [
    "# Check if file is in directory, else download it\n",
    "for county in county_list:\n",
    "    tiger_water_zip_file = \"tl_2013_{0}{1}_areawater.zip\".format(state_code, county)\n",
    "\n",
    "    if os.path.isfile(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_water_zip_file):\n",
    "        print \"Already had the file.  Great.\", tiger_water_zip_file\n",
    "    else:\n",
    "        r = requests.get(TIGER_BASE_URL + TIGER_WATER_DIR + tiger_water_zip_file)\n",
    "\n",
    "        if r.status_code == requests.codes.ok:\n",
    "            print(\"Got the file! Copying to disk.\")\n",
    "            with open(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_water_zip_file, \"wb\") as f:\n",
    "                f.write(r.content)\n",
    "        else:\n",
    "            print(\"Something went wrong. Status code: \".format(r.status_code))\n",
    "    \n",
    "    # Unzip file, extract contents\n",
    "    zfile = zipfile.ZipFile(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_water_zip_file)\n",
    "    zfile.extractall(LOCAL_DATA_DIR + GEO_SUB_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. WRITE SHAPE DATA TO GEOJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to  ./data/balt_city_geo_data.json\n"
     ]
    }
   ],
   "source": [
    "small_shapes = gpd.GeoDataFrame()\n",
    "small_shapes[\"geometry\"] = shapes[\"geometry\"].simplify(tolerance=0.0001) # Simplify geometry to reduce file size\n",
    "small_shapes[\"fips\"] = shapes[\"GEOID\"]\n",
    "small_shapes = small_shapes.set_index(\"fips\") # set index to the geo IDs of polygons\n",
    "\n",
    "small_json = small_shapes.to_json()\n",
    "\n",
    "# Write to file\n",
    "print \"Writing to \", geo_outfile\n",
    "with open(geo_outfile, 'w') as f:\n",
    "    f.write(small_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. GET CENSUS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B19001_002E</th>\n",
       "      <th>B19001_003E</th>\n",
       "      <th>B19001_004E</th>\n",
       "      <th>B19001_005E</th>\n",
       "      <th>B19001_006E</th>\n",
       "      <th>B19001_007E</th>\n",
       "      <th>B19001_008E</th>\n",
       "      <th>B19001_009E</th>\n",
       "      <th>B19001_010E</th>\n",
       "      <th>B19001_011E</th>\n",
       "      <th>B19001_012E</th>\n",
       "      <th>B19001_013E</th>\n",
       "      <th>B19001_014E</th>\n",
       "      <th>B19001_015E</th>\n",
       "      <th>B19001_016E</th>\n",
       "      <th>B19001_017E</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>tract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132</td>\n",
       "      <td>84</td>\n",
       "      <td>80</td>\n",
       "      <td>98</td>\n",
       "      <td>93</td>\n",
       "      <td>83</td>\n",
       "      <td>80</td>\n",
       "      <td>99</td>\n",
       "      <td>68</td>\n",
       "      <td>215</td>\n",
       "      <td>165</td>\n",
       "      <td>139</td>\n",
       "      <td>134</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>001</td>\n",
       "      <td>24</td>\n",
       "      <td>000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>92</td>\n",
       "      <td>78</td>\n",
       "      <td>43</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>75</td>\n",
       "      <td>61</td>\n",
       "      <td>24</td>\n",
       "      <td>108</td>\n",
       "      <td>127</td>\n",
       "      <td>141</td>\n",
       "      <td>99</td>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "      <td>17</td>\n",
       "      <td>001</td>\n",
       "      <td>24</td>\n",
       "      <td>000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>164</td>\n",
       "      <td>29</td>\n",
       "      <td>109</td>\n",
       "      <td>42</td>\n",
       "      <td>165</td>\n",
       "      <td>80</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>87</td>\n",
       "      <td>92</td>\n",
       "      <td>113</td>\n",
       "      <td>60</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>001</td>\n",
       "      <td>24</td>\n",
       "      <td>000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87</td>\n",
       "      <td>70</td>\n",
       "      <td>52</td>\n",
       "      <td>32</td>\n",
       "      <td>104</td>\n",
       "      <td>115</td>\n",
       "      <td>120</td>\n",
       "      <td>39</td>\n",
       "      <td>82</td>\n",
       "      <td>77</td>\n",
       "      <td>59</td>\n",
       "      <td>51</td>\n",
       "      <td>149</td>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>001</td>\n",
       "      <td>24</td>\n",
       "      <td>000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>354</td>\n",
       "      <td>134</td>\n",
       "      <td>72</td>\n",
       "      <td>53</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>59</td>\n",
       "      <td>14</td>\n",
       "      <td>38</td>\n",
       "      <td>97</td>\n",
       "      <td>35</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>001</td>\n",
       "      <td>24</td>\n",
       "      <td>000500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  B19001_002E B19001_003E B19001_004E B19001_005E B19001_006E B19001_007E  \\\n",
       "0         132          84          80          98          93          83   \n",
       "1          69          92          78          43          80          80   \n",
       "2          51         164          29         109          42         165   \n",
       "3          87          70          52          32         104         115   \n",
       "4         354         134          72          53          32          50   \n",
       "\n",
       "  B19001_008E B19001_009E B19001_010E B19001_011E B19001_012E B19001_013E  \\\n",
       "0          80          99          68         215         165         139   \n",
       "1          75          61          24         108         127         141   \n",
       "2          80          65          10          87          92         113   \n",
       "3         120          39          82          77          59          51   \n",
       "4          59          14          38          97          35          27   \n",
       "\n",
       "  B19001_014E B19001_015E B19001_016E B19001_017E county state   tract  \n",
       "0         134          17          14           0    001    24  000100  \n",
       "1          99          30          65          17    001    24  000200  \n",
       "2          60          79           0           8    001    24  000300  \n",
       "3         149          51           8          45    001    24  000400  \n",
       "4          26          32          13           0    001    24  000500  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get census tracts for the corresponding state\n",
    "for state_id in state_codes:\n",
    "    census_data = c.acs.get(var_ids, {'for': 'tract:*', 'in': 'state:{0}'.format(state_id)})\n",
    "    census_df = pd.DataFrame(census_data)\n",
    "    print state_id\n",
    "    display(census_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. CREATE CSV CENSUS FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting census dataframe to csv file.\n"
     ]
    }
   ],
   "source": [
    "# This segment of code will get household income estimates for each block group in state_code\n",
    "census_df = census_tracts_to_dataframe(var_ids, state_codes)\n",
    "census_df.to_csv(attr_outfile)\n",
    "\n",
    "print \"Converting census dataframe to csv file.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIONAL: CENSUS Tract Information LEVEL\n",
    "\n",
    "Use this code to get information at the tract level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On state_code:  24\n",
      "http://www2.census.gov/geo/tiger/TIGER2013/TRACT/tl_2013_24_tract.zip\n",
      "Already had the file.  Great. tl_2013_24_tract.zip\n"
     ]
    }
   ],
   "source": [
    "for state_id in state_codes:\n",
    "    tiger_zip_file = 'tl_2013_{0}_tract.zip'.format(state_id)\n",
    "    \n",
    "    FULL_TIGER_URL = TIGER_BASE_URL + TIGER_TRACT_DIR + tiger_zip_file\n",
    "    print \"On state_code: \", state_id\n",
    "    print FULL_TIGER_URL\n",
    "    \n",
    "    # Check if file is in directory, else download it\n",
    "    if os.path.isfile(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_zip_file):\n",
    "        print \"Already had the file.  Great.\", tiger_zip_file\n",
    "    else:\n",
    "        r = requests.get(FULL_TIGER_URL)\n",
    "\n",
    "        if r.status_code == requests.codes.ok:\n",
    "            print(\"Got the file! Copying to disk.\")\n",
    "            with open(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_zip_file, \"wb\") as f:\n",
    "                f.write(r.content)\n",
    "        else:\n",
    "            print(\"Something went wrong. Status code: \".format(r.status_code))\n",
    "            \n",
    "    # Unzip file, extract contents\n",
    "    zfile = zipfile.ZipFile(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_zip_file)\n",
    "    zfile.extractall(LOCAL_DATA_DIR + GEO_SUB_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
