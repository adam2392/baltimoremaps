{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Setup For Maps\n",
    "\n",
    "By: Adam Li\n",
    "\n",
    "Following tutorials on D3.js, I want to create maps of different cities in the USA for data visualization. To get the geodata of any city, I am using the US package: https://pypi.python.org/pypi/us, which provides detailed information about:\n",
    "* all US states and territories\n",
    "* postal abbreviations\n",
    "* Associated Press style abbreviations\n",
    "* FIPS codes\n",
    "* capitals\n",
    "* years of statehood\n",
    "* time zones\n",
    "* phonetic state name lookup\n",
    "* is contiguous or continental\n",
    "* URLs to shapefiles for state, census, congressional districts, counties, and census tracts\n",
    "\n",
    "## Methods:\n",
    "1. GET SHAPE GEO DATA: First we gather shape data from the TIGER site. This requires us to initialize the full tiger url, state code, county lists. Then we unzip the file and store it locally. Then we gather water data from the TIGER site. \n",
    "2. CREATE GEO DATA JSON: With the shape and water data, we create a geo_data.json file that can reproduce the geo map of the location we are interested in.\n",
    "3. CENSUS TRACT information: to populate the geojson areas with some sort of data\n",
    "4. CREATE CENSUS DATA CSV: using dataframes, convert to csv easily\n",
    "\n",
    "### References:\n",
    "- Census API: https://github.com/sunlightlabs/census\n",
    "- FIPS Explanation: https://www.policymap.com/blog/2012/08/tips-on-fips-a-quick-guide-to-geographic-place-codes-part-iii/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "from census import Census\n",
    "from us import states\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN FUNCTIONS: \n",
    "- build the fips code for a blockgroup\n",
    "- build fips code for tracts\n",
    "- converting census blockgroup to a panda dataframe\n",
    "- check if a directory exists and if not create it\n",
    "- convert census blockgroup to dataframe\n",
    "- convert census tract to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_bg_fips(record):\n",
    "    fips_code = record['state'] + record['county'] + record['tract'] + record['block group']\n",
    "    return str(fips_code)\n",
    "\n",
    "def build_tract_fips(record):\n",
    "    fips_code = record['state'] + record['county'] + record['tract']\n",
    "    return str(fips_code)\n",
    "\n",
    "def census_to_dataframe(var_list, state_code, county_codes):\n",
    "    fips_codes = []\n",
    "    all_records = []\n",
    "    \n",
    "    for county in county_codes:        \n",
    "        census_data = c.acs.get(var_list, {'for': 'block group:*', 'in': 'state:{0} county:{1}'.format(state_code, county)})\n",
    "        \n",
    "        for idx, record in enumerate(census_data):\n",
    "            # Build fips codes\n",
    "            fips_code = build_bg_fips(record)\n",
    "            census_data[idx][\"fips\"] = fips_code\n",
    "\n",
    "            # Eliminate original code components\n",
    "            key_list = ['state', 'county', 'tract', 'block group']\n",
    "            for key in key_list:\n",
    "                if key in census_data[idx]: \n",
    "                    del census_data[idx][key]\n",
    "        \n",
    "        all_records.extend(census_data)\n",
    "        \n",
    "    census_df = pd.DataFrame(all_records)\n",
    "    census_df = census_df.set_index(\"fips\")\n",
    "                \n",
    "    return census_df\n",
    "\n",
    "def checkDirExist(filepath):\n",
    "    if not os.path.exists(filepath):\n",
    "        os.makedirs(filepath)\n",
    "        \n",
    "def census_bg_to_dataframe(var_list, state_code, county_codes):\n",
    "    fips_codes = []\n",
    "    all_records = []\n",
    "    \n",
    "    for county in county_codes:        \n",
    "        census_data = c.acs.get(var_list, {'for': 'tract:*', 'in': 'state:{0}'.format(state_code)})\n",
    "        \n",
    "        for idx, record in enumerate(census_data):\n",
    "            # Build fips codes\n",
    "            fips_code = build_bg_fips(record)\n",
    "            census_data[idx][\"fips\"] = fips_code\n",
    "\n",
    "            # Eliminate original code components\n",
    "            key_list = ['state', 'county', 'tract', 'block group']\n",
    "            for key in key_list:\n",
    "                if key in census_data[idx]: \n",
    "                    del census_data[idx][key]\n",
    "        \n",
    "        all_records.extend(census_data)\n",
    "        \n",
    "    census_df = pd.DataFrame(all_records)\n",
    "    census_df = census_df.set_index(\"fips\")\n",
    "                \n",
    "    return census_df\n",
    "\n",
    "def census_tracts_to_dataframe(var_list, state_codes):\n",
    "    fips_codes = []\n",
    "    all_records = []\n",
    "    \n",
    "    for state_id in state_codes:\n",
    "        census_data = c.acs.get(var_list, {'for': 'tract:*', 'in': 'state:{0}'.format(state_id)})\n",
    "\n",
    "        for idx, record in enumerate(census_data):\n",
    "\n",
    "            # Build fips codes\n",
    "            fips_code = build_tract_fips(record)\n",
    "            census_data[idx][\"fips\"] = fips_code\n",
    "\n",
    "            # Eliminate original code components\n",
    "            key_list = ['state', 'county', 'tract']\n",
    "            for key in key_list:\n",
    "                if key in census_data[idx]: \n",
    "                    del census_data[idx][key]\n",
    "        \n",
    "        all_records.extend(census_data)\n",
    "      \n",
    "    census_df = pd.DataFrame(all_records)\n",
    "    census_df = census_df.set_index(\"fips\")\n",
    "                \n",
    "    return census_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize CENSUS API and URLs For Online GEO Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CENSUS API Stuff\n",
    "CENSUS_API = 'fe55211c8b3f0350fcb040c07321a129a3d6e266' # Your key here\n",
    "c = Census(CENSUS_API) # Initialize census class with API key\n",
    "\n",
    "# TIGER Stuff\n",
    "TIGER_BASE_URL = 'http://www2.census.gov/geo/tiger/TIGER2013/'\n",
    "TIGER_TRACT_DIR = 'TRACT/'\n",
    "TIGER_BLOCKGROUP_DIR = 'BG/'\n",
    "TIGER_WATER_DIR = 'AREAWATER/'\n",
    "\n",
    "# LOCAL DATA DIR FOR STORING THE DATA FROM CENSUS.GOV\n",
    "LOCAL_DATA_DIR = './data/'\n",
    "GEO_SUB_DIR = 'geo/'\n",
    "\n",
    "# FILE ENDINGS FOR FINAL DATA TO BE SAVED\n",
    "ATTR_FILE_END = '_census_data.csv'\n",
    "GEO_FILE_END = '_geo_data.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Settings for Which states, counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Specify state and county to download (select one)\n",
    "# loc_name, state_codes, county_codes = \"balt_city\", [states.MD.fips], list([510]) # Baltimore\n",
    "# Specify state and county to download (select one)\n",
    "# loc_name, state_codes, county_codes = 'maryland', states.MD.fips, None\n",
    "# loc_name, state_codes, county_codes = 'delmarva', [states.MD.fips, states.DE.fips, states.VA.fips], None\n",
    "# loc_name, state_codes, county_codes = 'california', states.CA.fips, None\n",
    "loc_name, state_codes, county_codes = \"california\", [states.CA.fips], list([6]) # Baltimore\n",
    "\n",
    "# Create county list (string representation of county IDs)\n",
    "try:\n",
    "    county_list = [\"{:03d}\".format(county_id) for county_id in county_codes]\n",
    "except:\n",
    "    print \"no county codes\"\n",
    "    \n",
    "# Generate codes for census variables of interest\n",
    "var_ids = [\"B19001_0{:02d}E\".format(x) for x in range(2, 18)] # Household income over 12 months\n",
    "\n",
    "attr_outfile = LOCAL_DATA_DIR + loc_name + ATTR_FILE_END\n",
    "geo_outfile = LOCAL_DATA_DIR + loc_name + GEO_FILE_END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State code is:  [u'06']\n",
      "['006']\n",
      "['B19001_002E', 'B19001_003E', 'B19001_004E', 'B19001_005E', 'B19001_006E', 'B19001_007E', 'B19001_008E', 'B19001_009E', 'B19001_010E', 'B19001_011E', 'B19001_012E', 'B19001_013E', 'B19001_014E', 'B19001_015E', 'B19001_016E', 'B19001_017E']\n",
      "california\n"
     ]
    }
   ],
   "source": [
    "print \"State code is: \", state_codes\n",
    "print county_list\n",
    "print var_ids\n",
    "print loc_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get TIGER data (shape data) From TIGER\n",
    "\n",
    "### get data by state at the blockgroup level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On state_code:  06\n",
      "http://www2.census.gov/geo/tiger/TIGER2013/BG/tl_2013_06_bg.zip\n",
      "Already had the file.  Great. tl_2013_06_bg.zip\n"
     ]
    }
   ],
   "source": [
    "for state_id in state_codes:\n",
    "    tiger_zip_file = 'tl_2013_{0}_bg.zip'.format(state_id)\n",
    "\n",
    "    FULL_TIGER_URL = TIGER_BASE_URL + TIGER_BLOCKGROUP_DIR + tiger_zip_file\n",
    "    print \"On state_code: \", state_id\n",
    "    print FULL_TIGER_URL\n",
    "\n",
    "    # Check if file is in directory, else download it\n",
    "    if os.path.isfile(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_zip_file):\n",
    "        print \"Already had the file.  Great.\", tiger_zip_file\n",
    "    else:\n",
    "        r = requests.get(FULL_TIGER_URL)\n",
    "\n",
    "        if r.status_code == requests.codes.ok:\n",
    "            print \"Got files, copying to disk...\"\n",
    "            checkDirExist(LOCAL_DATA_DIR + GEO_SUB_DIR)\n",
    "            with open(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_zip_file, 'wb') as f:\n",
    "                f.write(r.content)\n",
    "        else:\n",
    "            print \"Error with getting the data. Status code: \".format(r.status_code)\n",
    "            print \"Download files directly from: \", TIGER_BASE_URL + TIGER_BLOCKGROUP_DIR\n",
    "            print \"Download \", tiger_zip_file\n",
    "            \n",
    "    # Unzip file, extract contents\n",
    "    zfile = zipfile.ZipFile(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_zip_file)\n",
    "    zfile.extractall(LOCAL_DATA_DIR + GEO_SUB_DIR)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GeoPD from:  tl_2013_06_bg.shp\n",
      "Only keeping counties in:  ['006']\n",
      "The shape of the new dataframe is:  (0, 13)\n"
     ]
    }
   ],
   "source": [
    "state_shapes = [] # list of geodataframes\n",
    "for idx, state_id in enumerate(state_codes):\n",
    "    tiger_shape_file = 'tl_2013_{0}_bg.shp'.format(state_id)\n",
    "    print \"Loading GeoPD from: \", tiger_shape_file\n",
    "\n",
    "    # Load to GeoDataFrame\n",
    "    state_shape = gpd.GeoDataFrame.from_file(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_shape_file)\n",
    "    # Only keep counties that we are interested in\n",
    "    if county_list is not None:\n",
    "        print \"Only keeping counties in: \", county_list\n",
    "        state_shape = state_shape[state_shape[\"COUNTYFP\"].isin(county_list)]\n",
    "    \n",
    "    state_shapes.append(state_shape)\n",
    "       \n",
    "# concatenate the dataframes from the tract level\n",
    "shapes = gpd.GeoDataFrame( pd.concat(state_shapes, ignore_index=True) )\n",
    "\n",
    "print \"The shape of the new dataframe is: \", shapes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET TIGER (water data) from Site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something went wrong. Status code: \n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: './data/geo/tl_2013_06006_areawater.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b8da3e3fd573>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Unzip file, extract contents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mzfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOCAL_DATA_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mGEO_SUB_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtiger_water_zip_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mzfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOCAL_DATA_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mGEO_SUB_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.11/Frameworks/Python.framework/Versions/2.7/lib/python2.7/zipfile.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64)\u001b[0m\n\u001b[1;32m    754\u001b[0m             \u001b[0mmodeDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'r'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'r+b'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: './data/geo/tl_2013_06006_areawater.zip'"
     ]
    }
   ],
   "source": [
    "for state_id in state_codes:\n",
    "    # Check if file is in directory, else download it\n",
    "    for county in county_list:\n",
    "        tiger_water_zip_file = \"tl_2013_{0}{1}_areawater.zip\".format(state_id, county)\n",
    "\n",
    "        if os.path.isfile(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_water_zip_file):\n",
    "            print \"Already had the file.  Great.\", tiger_water_zip_file\n",
    "        else:\n",
    "            r = requests.get(TIGER_BASE_URL + TIGER_WATER_DIR + tiger_water_zip_file)\n",
    "\n",
    "            if r.status_code == requests.codes.ok:\n",
    "                print(\"Got the file! Copying to disk.\")\n",
    "                with open(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_water_zip_file, \"wb\") as f:\n",
    "                    f.write(r.content)\n",
    "            else:\n",
    "                print(\"Something went wrong. Status code: \".format(r.status_code))\n",
    "\n",
    "        # Unzip file, extract contents\n",
    "        zfile = zipfile.ZipFile(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_water_zip_file)\n",
    "        zfile.extractall(LOCAL_DATA_DIR + GEO_SUB_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. WRITE SHAPE DATA TO GEOJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to  ./data/california_geo_data.json\n"
     ]
    }
   ],
   "source": [
    "small_shapes = gpd.GeoDataFrame()\n",
    "small_shapes[\"geometry\"] = shapes[\"geometry\"].simplify(tolerance=0.0001) # Simplify geometry to reduce file size\n",
    "small_shapes[\"fips\"] = shapes[\"GEOID\"]\n",
    "small_shapes = small_shapes.set_index(\"fips\") # set index to the geo IDs of polygons\n",
    "\n",
    "small_json = small_shapes.to_json()\n",
    "\n",
    "# Write to file\n",
    "print \"Writing to \", geo_outfile\n",
    "with open(geo_outfile, 'w') as f:\n",
    "    f.write(small_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. GET CENSUS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B19001_002E</th>\n",
       "      <th>B19001_003E</th>\n",
       "      <th>B19001_004E</th>\n",
       "      <th>B19001_005E</th>\n",
       "      <th>B19001_006E</th>\n",
       "      <th>B19001_007E</th>\n",
       "      <th>B19001_008E</th>\n",
       "      <th>B19001_009E</th>\n",
       "      <th>B19001_010E</th>\n",
       "      <th>B19001_011E</th>\n",
       "      <th>B19001_012E</th>\n",
       "      <th>B19001_013E</th>\n",
       "      <th>B19001_014E</th>\n",
       "      <th>B19001_015E</th>\n",
       "      <th>B19001_016E</th>\n",
       "      <th>B19001_017E</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>tract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>26</td>\n",
       "      <td>147</td>\n",
       "      <td>147</td>\n",
       "      <td>72</td>\n",
       "      <td>167</td>\n",
       "      <td>530</td>\n",
       "      <td>001</td>\n",
       "      <td>06</td>\n",
       "      <td>400100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>31</td>\n",
       "      <td>60</td>\n",
       "      <td>58</td>\n",
       "      <td>110</td>\n",
       "      <td>96</td>\n",
       "      <td>107</td>\n",
       "      <td>251</td>\n",
       "      <td>001</td>\n",
       "      <td>06</td>\n",
       "      <td>400200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>308</td>\n",
       "      <td>66</td>\n",
       "      <td>32</td>\n",
       "      <td>67</td>\n",
       "      <td>95</td>\n",
       "      <td>41</td>\n",
       "      <td>76</td>\n",
       "      <td>79</td>\n",
       "      <td>271</td>\n",
       "      <td>159</td>\n",
       "      <td>206</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>224</td>\n",
       "      <td>465</td>\n",
       "      <td>001</td>\n",
       "      <td>06</td>\n",
       "      <td>400300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71</td>\n",
       "      <td>58</td>\n",
       "      <td>60</td>\n",
       "      <td>47</td>\n",
       "      <td>51</td>\n",
       "      <td>66</td>\n",
       "      <td>33</td>\n",
       "      <td>53</td>\n",
       "      <td>17</td>\n",
       "      <td>70</td>\n",
       "      <td>123</td>\n",
       "      <td>273</td>\n",
       "      <td>245</td>\n",
       "      <td>185</td>\n",
       "      <td>234</td>\n",
       "      <td>226</td>\n",
       "      <td>001</td>\n",
       "      <td>06</td>\n",
       "      <td>400400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>87</td>\n",
       "      <td>89</td>\n",
       "      <td>26</td>\n",
       "      <td>67</td>\n",
       "      <td>17</td>\n",
       "      <td>107</td>\n",
       "      <td>172</td>\n",
       "      <td>308</td>\n",
       "      <td>231</td>\n",
       "      <td>62</td>\n",
       "      <td>106</td>\n",
       "      <td>68</td>\n",
       "      <td>001</td>\n",
       "      <td>06</td>\n",
       "      <td>400500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  B19001_002E B19001_003E B19001_004E B19001_005E B19001_006E B19001_007E  \\\n",
       "0          32          11          39           8          19          41   \n",
       "1          15           0          10           7           0           9   \n",
       "2          67         308          66          32          67          95   \n",
       "3          71          58          60          47          51          66   \n",
       "4          38         138           0          74          87          89   \n",
       "\n",
       "  B19001_008E B19001_009E B19001_010E B19001_011E B19001_012E B19001_013E  \\\n",
       "0           0           0           0          61          26         147   \n",
       "1          22           5          34          31          60          58   \n",
       "2          41          76          79         271         159         206   \n",
       "3          33          53          17          70         123         273   \n",
       "4          26          67          17         107         172         308   \n",
       "\n",
       "  B19001_014E B19001_015E B19001_016E B19001_017E county state   tract  \n",
       "0         147          72         167         530    001    06  400100  \n",
       "1         110          96         107         251    001    06  400200  \n",
       "2         175         179         224         465    001    06  400300  \n",
       "3         245         185         234         226    001    06  400400  \n",
       "4         231          62         106          68    001    06  400500  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get census tracts for the corresponding state\n",
    "for state_id in state_codes:\n",
    "    census_data = c.acs.get(var_ids, {'for': 'tract:*', 'in': 'state:{0}'.format(state_id)})\n",
    "    census_df = pd.DataFrame(census_data)\n",
    "    print state_id\n",
    "    display(census_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. CREATE CSV CENSUS FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting census dataframe to csv file.\n"
     ]
    }
   ],
   "source": [
    "# This segment of code will get household income estimates for each block group in state_code\n",
    "census_df = census_tracts_to_dataframe(var_ids, state_codes)\n",
    "census_df.to_csv(attr_outfile)\n",
    "\n",
    "print \"Converting census dataframe to csv file.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIONAL: CENSUS Tract Information LEVEL\n",
    "\n",
    "Use this code to get information at the tract level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On state_code:  06\n",
      "http://www2.census.gov/geo/tiger/TIGER2013/TRACT/tl_2013_06_tract.zip\n",
      "Already had the file.  Great. tl_2013_06_tract.zip\n",
      "Loading GeoPD from:  tl_2013_06_tract.shp\n",
      "The shape of the new dataframe is:  (8057, 13)\n",
      "Writing to  ./data/california_geo_data.json\n",
      "06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B19001_002E</th>\n",
       "      <th>B19001_003E</th>\n",
       "      <th>B19001_004E</th>\n",
       "      <th>B19001_005E</th>\n",
       "      <th>B19001_006E</th>\n",
       "      <th>B19001_007E</th>\n",
       "      <th>B19001_008E</th>\n",
       "      <th>B19001_009E</th>\n",
       "      <th>B19001_010E</th>\n",
       "      <th>B19001_011E</th>\n",
       "      <th>B19001_012E</th>\n",
       "      <th>B19001_013E</th>\n",
       "      <th>B19001_014E</th>\n",
       "      <th>B19001_015E</th>\n",
       "      <th>B19001_016E</th>\n",
       "      <th>B19001_017E</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>tract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>26</td>\n",
       "      <td>147</td>\n",
       "      <td>147</td>\n",
       "      <td>72</td>\n",
       "      <td>167</td>\n",
       "      <td>530</td>\n",
       "      <td>001</td>\n",
       "      <td>06</td>\n",
       "      <td>400100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>31</td>\n",
       "      <td>60</td>\n",
       "      <td>58</td>\n",
       "      <td>110</td>\n",
       "      <td>96</td>\n",
       "      <td>107</td>\n",
       "      <td>251</td>\n",
       "      <td>001</td>\n",
       "      <td>06</td>\n",
       "      <td>400200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>308</td>\n",
       "      <td>66</td>\n",
       "      <td>32</td>\n",
       "      <td>67</td>\n",
       "      <td>95</td>\n",
       "      <td>41</td>\n",
       "      <td>76</td>\n",
       "      <td>79</td>\n",
       "      <td>271</td>\n",
       "      <td>159</td>\n",
       "      <td>206</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>224</td>\n",
       "      <td>465</td>\n",
       "      <td>001</td>\n",
       "      <td>06</td>\n",
       "      <td>400300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71</td>\n",
       "      <td>58</td>\n",
       "      <td>60</td>\n",
       "      <td>47</td>\n",
       "      <td>51</td>\n",
       "      <td>66</td>\n",
       "      <td>33</td>\n",
       "      <td>53</td>\n",
       "      <td>17</td>\n",
       "      <td>70</td>\n",
       "      <td>123</td>\n",
       "      <td>273</td>\n",
       "      <td>245</td>\n",
       "      <td>185</td>\n",
       "      <td>234</td>\n",
       "      <td>226</td>\n",
       "      <td>001</td>\n",
       "      <td>06</td>\n",
       "      <td>400400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>87</td>\n",
       "      <td>89</td>\n",
       "      <td>26</td>\n",
       "      <td>67</td>\n",
       "      <td>17</td>\n",
       "      <td>107</td>\n",
       "      <td>172</td>\n",
       "      <td>308</td>\n",
       "      <td>231</td>\n",
       "      <td>62</td>\n",
       "      <td>106</td>\n",
       "      <td>68</td>\n",
       "      <td>001</td>\n",
       "      <td>06</td>\n",
       "      <td>400500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  B19001_002E B19001_003E B19001_004E B19001_005E B19001_006E B19001_007E  \\\n",
       "0          32          11          39           8          19          41   \n",
       "1          15           0          10           7           0           9   \n",
       "2          67         308          66          32          67          95   \n",
       "3          71          58          60          47          51          66   \n",
       "4          38         138           0          74          87          89   \n",
       "\n",
       "  B19001_008E B19001_009E B19001_010E B19001_011E B19001_012E B19001_013E  \\\n",
       "0           0           0           0          61          26         147   \n",
       "1          22           5          34          31          60          58   \n",
       "2          41          76          79         271         159         206   \n",
       "3          33          53          17          70         123         273   \n",
       "4          26          67          17         107         172         308   \n",
       "\n",
       "  B19001_014E B19001_015E B19001_016E B19001_017E county state   tract  \n",
       "0         147          72         167         530    001    06  400100  \n",
       "1         110          96         107         251    001    06  400200  \n",
       "2         175         179         224         465    001    06  400300  \n",
       "3         245         185         234         226    001    06  400400  \n",
       "4         231          62         106          68    001    06  400500  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting census dataframe to csv file.\n",
      "./data/california_census_data.csv\n"
     ]
    }
   ],
   "source": [
    "county_list = None\n",
    "\n",
    "for state_id in state_codes:\n",
    "    tiger_zip_file = 'tl_2013_{0}_tract.zip'.format(state_id)\n",
    "    \n",
    "    FULL_TIGER_URL = TIGER_BASE_URL + TIGER_TRACT_DIR + tiger_zip_file\n",
    "    print \"On state_code: \", state_id\n",
    "    print FULL_TIGER_URL\n",
    "    \n",
    "    # Check if file is in directory, else download it\n",
    "    if os.path.isfile(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_zip_file):\n",
    "        print \"Already had the file.  Great.\", tiger_zip_file\n",
    "    else:\n",
    "        r = requests.get(FULL_TIGER_URL)\n",
    "\n",
    "        if r.status_code == requests.codes.ok:\n",
    "            print(\"Got the file! Copying to disk.\")\n",
    "            with open(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_zip_file, \"wb\") as f:\n",
    "                f.write(r.content)\n",
    "        else:\n",
    "            print(\"Something went wrong. Status code: \".format(r.status_code))\n",
    "            \n",
    "    # Unzip file, extract contents\n",
    "    zfile = zipfile.ZipFile(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_zip_file)\n",
    "    zfile.extractall(LOCAL_DATA_DIR + GEO_SUB_DIR)\n",
    "    \n",
    "state_shapes = [] # list of geodataframes\n",
    "for idx, state_id in enumerate(state_codes):\n",
    "    tiger_shape_file = 'tl_2013_{0}_tract.shp'.format(state_id)\n",
    "    print \"Loading GeoPD from: \", tiger_shape_file\n",
    "\n",
    "    # Load to GeoDataFrame\n",
    "    state_shape = gpd.GeoDataFrame.from_file(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_shape_file)\n",
    "    # Only keep counties that we are interested in\n",
    "    if county_list is not None:\n",
    "        print \"Only keeping counties in: \", county_list\n",
    "        state_shape = state_shape[state_shape[\"COUNTYFP\"].isin(county_list)]\n",
    "    \n",
    "    state_shapes.append(state_shape)\n",
    "       \n",
    "# concatenate the dataframes from the tract level\n",
    "shapes = gpd.GeoDataFrame( pd.concat(state_shapes, ignore_index=True) )\n",
    "\n",
    "print \"The shape of the new dataframe is: \", shapes.shape\n",
    "\n",
    "small_shapes = gpd.GeoDataFrame()\n",
    "small_shapes[\"geometry\"] = shapes[\"geometry\"].simplify(tolerance=0.0001) # Simplify geometry to reduce file size\n",
    "small_shapes[\"fips\"] = shapes[\"GEOID\"]\n",
    "small_shapes = small_shapes.set_index(\"fips\") # set index to the geo IDs of polygons\n",
    "\n",
    "small_json = small_shapes.to_json()\n",
    "\n",
    "# Write to file\n",
    "print \"Writing to \", geo_outfile\n",
    "with open(geo_outfile, 'w') as f:\n",
    "    f.write(small_json)\n",
    "    \n",
    "# get census tracts for the corresponding state\n",
    "for state_id in state_codes:\n",
    "    census_data = c.acs.get(var_ids, {'for': 'tract:*', 'in': 'state:{0}'.format(state_id)})\n",
    "    census_df = pd.DataFrame(census_data)\n",
    "    print state_id\n",
    "    display(census_df.head())\n",
    "\n",
    "# This segment of code will get household income estimates for each block group in state_code\n",
    "census_df = census_tracts_to_dataframe(var_ids, state_codes)\n",
    "census_df.to_csv(attr_outfile)\n",
    "\n",
    "print \"Converting census dataframe to csv file.\"\n",
    "print attr_outfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Prototype Look at Political Party Data\n",
    "From https://www.theguardian.com/news/datablog/2012/nov/07/us-2012-election-county-results-download#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County Name</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Obama vote</th>\n",
       "      <th>%</th>\n",
       "      <th>Romney vote</th>\n",
       "      <th>%.1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State Postal</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0</td>\n",
       "      <td>91,696</td>\n",
       "      <td>41.6</td>\n",
       "      <td>121,234</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>2000</td>\n",
       "      <td>91,696</td>\n",
       "      <td>41.6</td>\n",
       "      <td>121,234</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>0</td>\n",
       "      <td>793,620</td>\n",
       "      <td>38.4</td>\n",
       "      <td>1,252,453</td>\n",
       "      <td>60.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>Autauga</td>\n",
       "      <td>1001</td>\n",
       "      <td>6,354</td>\n",
       "      <td>26.6</td>\n",
       "      <td>17,366</td>\n",
       "      <td>72.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>Baldwin</td>\n",
       "      <td>1003</td>\n",
       "      <td>18,329</td>\n",
       "      <td>21.6</td>\n",
       "      <td>65,772</td>\n",
       "      <td>77.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             County Name  FIPS Obama vote     % Romney vote   %.1\n",
       "State Postal                                                     \n",
       "AK                Alaska     0     91,696  41.6     121,234    55\n",
       "AK                Alaska  2000     91,696  41.6     121,234    55\n",
       "AL               Alabama     0    793,620  38.4   1,252,453  60.7\n",
       "AL               Autauga  1001      6,354  26.6      17,366  72.6\n",
       "AL               Baldwin  1003     18,329  21.6      65,772  77.4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "POL_FILE = './data/raw/US_elect_county.csv'\n",
    "pol_data = pd.DataFrame.from_csv(POL_FILE)\n",
    "display(pol_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State Postal</th>\n",
       "      <th>State</th>\n",
       "      <th>Dem Vote</th>\n",
       "      <th>Rep Vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>AK</td>\n",
       "      <td>91,696</td>\n",
       "      <td>121,234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>AK</td>\n",
       "      <td>91,696</td>\n",
       "      <td>121,234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>AL</td>\n",
       "      <td>793,620</td>\n",
       "      <td>1,252,453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>AL</td>\n",
       "      <td>6,354</td>\n",
       "      <td>17,366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL</td>\n",
       "      <td>AL</td>\n",
       "      <td>18,329</td>\n",
       "      <td>65,772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State Postal State Dem Vote   Rep Vote\n",
       "0           AK    AK   91,696    121,234\n",
       "1           AK    AK   91,696    121,234\n",
       "2           AL    AL  793,620  1,252,453\n",
       "3           AL    AL    6,354     17,366\n",
       "4           AL    AL   18,329     65,772"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AK' 'AL' 'AR' 'AZ' 'CA' 'DC' 'DE' 'HI' 'IA' 'ID' 'IL' 'IN' 'KS' 'KY' 'LA'\n",
      " 'MA' 'MD' 'ME' 'MI' 'MN' 'MO' 'MS' 'MT' 'NC' 'ND' 'NE' 'NH' 'NJ' 'NM' 'NV'\n",
      " 'NY' 'OH' 'OK' 'OR' 'PA' 'RI' 'SD' 'TN' 'TX' 'VA' 'VT' 'WA' 'WI' 'WV']\n"
     ]
    }
   ],
   "source": [
    "# filter by state\n",
    "# states = ['MD']\n",
    "# df = pol_data[pol_data['State Postal'].isin(states)]\n",
    "\n",
    "pol_data['State Postal'] = pol_data.index\n",
    "df = pol_data\n",
    "# clean up datea a bit and resave it\n",
    "df_data = pd.DataFrame()\n",
    "df_data['State'] = df['State Postal']\n",
    "df_data['Dem Vote'] = df['Obama vote']\n",
    "df_data['Rep Vote'] = df['Romney vote']\n",
    "df_data = df_data.reset_index()\n",
    "display(df_data.head())\n",
    "print pd.Series.unique(df_data['State'])\n",
    "\n",
    "# save the dataframe \n",
    "pol_outfile = 'data/USA_pol_data.csv'\n",
    "df_data.to_csv(pol_outfile)\n",
    "\n",
    "# This segment of code will get household income estimates for each block group in state_code\n",
    "# census_df = census_tracts_to_dataframe(var_ids, state_codes)\n",
    "# census_df.to_csv(attr_outfile)\n",
    "# # Write to file\n",
    "# print \"Writing to \", geo_outfile\n",
    "# with open(geo_outfile, 'w') as f:\n",
    "#     f.write(small_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running OGR2OGR and TopoJSON\n",
    "\n",
    "ogr2ogr \\\n",
    "  -f GeoJSON \\ //telling it to convert to geo json\n",
    "  subunits.json \\ //output file name\n",
    "  ne_10m_admin_0_map_subunits.shp //the shape file!\n",
    "  \n",
    "After this, you have a geojson file that is relatively large, so we can use TopoJSON format to reduce filesize.\n",
    "\n",
    "topojson \\\n",
    "  -o uk.json \\ //output file name\n",
    "  subunits.json \\\n",
    "  places.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: \n",
    "http://www.tnoda.com/blog/2013-12-07\n",
    "\n",
    "1. Download files from: \n",
    "    * http://www.naturalearthdata.com/http//www.naturalearthdata.com/download/10m/cultural/ne_10m_admin_0_countries_lakes.zip\n",
    "\n",
    "    * http://www.naturalearthdata.com/http//www.naturalearthdata.com/download/10m/cultural/ne_10m_admin_1_states_provinces_lakes.zip\n",
    "\n",
    "    * http://www.naturalearthdata.com/http//www.naturalearthdata.com/download/10m/cultural/ne_10m_populated_places.zip\n",
    "\n",
    "2. Convert Files to GeoJSON -> TopoJSON\n",
    "\n",
    "    ogr2ogr -f GeoJSON -where \"ADM0_A3 IN ('USA')\" usa.json ne_10m_admin_0_countries_lakes.shp\n",
    "\n",
    "    -> to only get the USA data\n",
    "\n",
    "    topojson --id-property SU_A3 -p name=NAME -p name -o usa.topo.json usa.json\n",
    "\n",
    "    -> to convert GeoJSON into TopoJSON file format\n",
    "\n",
    "3. Read in D3 and display data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
