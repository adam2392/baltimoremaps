{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Setup For Maps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "from census import Census\n",
    "from us import states\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_bg_fips(record):\n",
    "    fips_code = record['state'] + record['county'] + record['tract'] + record['block group']\n",
    "    return str(fips_code)\n",
    "\n",
    "def build_tract_fips(record):\n",
    "    fips_code = record['state'] + record['county'] + record['tract']\n",
    "    return str(fips_code)\n",
    "\n",
    "def census_to_dataframe(var_list, state_code, county_codes):\n",
    "    fips_codes = []\n",
    "    all_records = []\n",
    "    \n",
    "    for county in county_codes:        \n",
    "        census_data = c.acs.get(var_list, {'for': 'block group:*', 'in': 'state:{0} county:{1}'.format(state_code, county)})\n",
    "        \n",
    "        for idx, record in enumerate(census_data):\n",
    "            # Build fips codes\n",
    "            fips_code = build_bg_fips(record)\n",
    "            census_data[idx][\"fips\"] = fips_code\n",
    "\n",
    "            # Eliminate original code components\n",
    "            key_list = ['state', 'county', 'tract', 'block group']\n",
    "            for key in key_list:\n",
    "                if key in census_data[idx]: \n",
    "                    del census_data[idx][key]\n",
    "        \n",
    "        all_records.extend(census_data)\n",
    "        \n",
    "    census_df = pd.DataFrame(all_records)\n",
    "    census_df = census_df.set_index(\"fips\")\n",
    "                \n",
    "    return census_df\n",
    "\n",
    "def checkDirExist(filepath):\n",
    "    if not os.path.exists(filepath):\n",
    "        os.makedirs(filepath)\n",
    "        \n",
    "def census_bg_to_dataframe(var_list, state_code, county_codes):\n",
    "    fips_codes = []\n",
    "    all_records = []\n",
    "    \n",
    "    for county in county_codes:        \n",
    "        census_data = c.acs.get(var_list, {'for': 'tract:*', 'in': 'state:{0}'.format(state_code)})\n",
    "        \n",
    "        for idx, record in enumerate(census_data):\n",
    "            # Build fips codes\n",
    "            fips_code = build_bg_fips(record)\n",
    "            census_data[idx][\"fips\"] = fips_code\n",
    "\n",
    "            # Eliminate original code components\n",
    "            key_list = ['state', 'county', 'tract', 'block group']\n",
    "            for key in key_list:\n",
    "                if key in census_data[idx]: \n",
    "                    del census_data[idx][key]\n",
    "        \n",
    "        all_records.extend(census_data)\n",
    "        \n",
    "    census_df = pd.DataFrame(all_records)\n",
    "    census_df = census_df.set_index(\"fips\")\n",
    "                \n",
    "    return census_df\n",
    "\n",
    "def census_tracts_to_dataframe(var_list, state_codes):\n",
    "    fips_codes = []\n",
    "    all_records = []\n",
    "    \n",
    "    for state_id in state_codes:\n",
    "        census_data = c.acs.get(var_list, {'for': 'tract:*', 'in': 'state:{0}'.format(state_id)})\n",
    "\n",
    "        for idx, record in enumerate(census_data):\n",
    "\n",
    "            # Build fips codes\n",
    "            fips_code = build_tract_fips(record)\n",
    "            census_data[idx][\"fips\"] = fips_code\n",
    "\n",
    "            # Eliminate original code components\n",
    "            key_list = ['state', 'county', 'tract']\n",
    "            for key in key_list:\n",
    "                if key in census_data[idx]: \n",
    "                    del census_data[idx][key]\n",
    "        \n",
    "        all_records.extend(census_data)\n",
    "      \n",
    "    census_df = pd.DataFrame(all_records)\n",
    "    census_df = census_df.set_index(\"fips\")\n",
    "                \n",
    "    return census_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Specify state and county to download (select one)\n",
    "loc_name, state_code, county_codes = \"balt_city\", states.MD.fips, list([510]) # Baltimore\n",
    "\n",
    "# Create county list (string representation of county IDs)\n",
    "county_list = [\"{:03d}\".format(county_id) for county_id in county_codes]\n",
    "\n",
    "# CENSUS API Stuff\n",
    "CENSUS_API = 'fe55211c8b3f0350fcb040c07321a129a3d6e266' # Your key here\n",
    "c = Census(CENSUS_API) # Initialize census class with API key\n",
    "\n",
    "# Generate codes for census variables of interest\n",
    "var_ids = [\"B19001_0{:02d}E\".format(x) for x in range(2, 18)] # Household income over 12 months\n",
    "\n",
    "# TIGER Stuff\n",
    "TIGER_BASE_URL = 'http://www2.census.gov/geo/tiger/TIGER2013/'\n",
    "TIGER_TRACT_DIR = 'TRACT/'\n",
    "TIGER_BLOCKGROUP_DIR = 'BG/'\n",
    "TIGER_WATER_DIR = 'AREAWATER/'\n",
    "\n",
    "# LOCAL DATA DIR FOR STORING THE DATA FROM CENSUS.GOV\n",
    "LOCAL_DATA_DIR = './data/'\n",
    "GEO_SUB_DIR = 'geo/'\n",
    "\n",
    "# GET FILE BY STATE_CODE\n",
    "tiger_zip_file = 'tl_2013_{0}_bg.zip'.format(state_code)\n",
    "tiger_shape_file = 'tl_2013_{0}_bg.shp'.format(state_code)\n",
    "\n",
    "ATTR_FILE_END = '_census_data.csv'\n",
    "attr_outfile = LOCAL_DATA_DIR + loc_name + ATTR_FILE_END\n",
    "\n",
    "GEO_FILE_END = '_geo_data.json'\n",
    "geo_outfile = LOCAL_DATA_DIR + loc_name + GEO_FILE_END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maryland state code is:  24\n",
      "['510']\n",
      "['B19001_002E', 'B19001_003E', 'B19001_004E', 'B19001_005E', 'B19001_006E', 'B19001_007E', 'B19001_008E', 'B19001_009E', 'B19001_010E', 'B19001_011E', 'B19001_012E', 'B19001_013E', 'B19001_014E', 'B19001_015E', 'B19001_016E', 'B19001_017E']\n",
      "tl_2013_24_bg.zip\n",
      "tl_2013_24_bg.shp\n"
     ]
    }
   ],
   "source": [
    "print \"Maryland state code is: \", state_code\n",
    "print county_list\n",
    "print var_ids\n",
    "print tiger_zip_file\n",
    "print tiger_shape_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get TIGER data (shape data) From Census API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www2.census.gov/geo/tiger/TIGER2013/BG/tl_2013_24_bg.zip\n",
      "Already had the file.  Great.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "FULL_TIGER_URL = TIGER_BASE_URL + TIGER_BLOCKGROUP_DIR + tiger_zip_file\n",
    "print FULL_TIGER_URL\n",
    "\n",
    "# Check if file is in directory, else download it\n",
    "if os.path.isfile(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_zip_file):\n",
    "    print \"Already had the file.  Great.\"\n",
    "else:\n",
    "    r = requests.get(FULL_TIGER_URL)\n",
    "    \n",
    "    if r.status_code == requests.codes.ok:\n",
    "        print \"Got files, copying to disk...\"\n",
    "        checkDirExist(LOCAL_DATA_DIR + GEO_SUB_DIR)\n",
    "        with open(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_zip_file, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "    else:\n",
    "        print \"Error with getting the data. Status code: \".format(r.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3926, 13)\n"
     ]
    }
   ],
   "source": [
    "# Unzip file, extract contents\n",
    "zfile = zipfile.ZipFile(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_zip_file)\n",
    "zfile.extractall(LOCAL_DATA_DIR + GEO_SUB_DIR)\n",
    "\n",
    "# Load to GeoDataFrame the shape file\n",
    "shapes = gpd.GeoDataFrame.from_file(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_shape_file)\n",
    "\n",
    "print shapes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(653, 13)\n",
      "Index([   u'ALAND',   u'AWATER', u'BLKGRPCE', u'COUNTYFP', u'FUNCSTAT',\n",
      "          u'GEOID', u'INTPTLAT', u'INTPTLON',    u'MTFCC', u'NAMELSAD',\n",
      "        u'STATEFP',  u'TRACTCE', u'geometry'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Only keep counties that we are interested in\n",
    "shapes = shapes[shapes[\"COUNTYFP\"].isin(county_list)]\n",
    "print shapes.shape\n",
    "print shapes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already had the file.  Great.\n"
     ]
    }
   ],
   "source": [
    "# Check if file is in directory, else download it\n",
    "for county in county_list:\n",
    "    tiger_water_zip_file = \"tl_2013_{0}{1}_areawater.zip\".format(state_code, county)\n",
    "\n",
    "    if os.path.isfile(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_water_zip_file):\n",
    "        print(\"Already had the file.  Great.\")\n",
    "    else:\n",
    "        r = requests.get(TIGER_BASE_URL + TIGER_WATER_DIR + tiger_water_zip_file)\n",
    "\n",
    "        if r.status_code == requests.codes.ok:\n",
    "            print(\"Got the file! Copying to disk.\")\n",
    "            with open(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_water_zip_file, \"wb\") as f:\n",
    "                f.write(r.content)\n",
    "        else:\n",
    "            print(\"Something went wrong. Status code: \".format(r.status_code))\n",
    "    \n",
    "    # Unzip file, extract contents\n",
    "    zfile = zipfile.ZipFile(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_water_zip_file)\n",
    "    zfile.extractall(LOCAL_DATA_DIR + GEO_SUB_DIR)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to  ./data/balt_city_geo_data.json\n"
     ]
    }
   ],
   "source": [
    "small_shapes = gpd.GeoDataFrame()\n",
    "small_shapes[\"geometry\"] = shapes[\"geometry\"].simplify(tolerance=0.0001) # Simplify geometry to reduce file size\n",
    "small_shapes[\"fips\"] = shapes[\"GEOID\"]\n",
    "small_shapes = small_shapes.set_index(\"fips\") # set index to the geo IDs of polygons\n",
    "\n",
    "small_json = small_shapes.to_json()\n",
    "\n",
    "# Write to file\n",
    "print \"Writing to \", geo_outfile\n",
    "with open(geo_outfile, 'w') as f:\n",
    "    f.write(small_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "loc_name, state_codes, county_codes = 'maryland', states.MD.fips, None\n",
    "loc_name, state_codes, county_codes = 'delmarva', [states.MD.fips, states.DE.fips, states.VA.fips], None\n",
    "\n",
    "if county_codes is not None:\n",
    "    county_list = [\"{:03d}\".format(county_id) for county_id in county_codes]\n",
    "else:\n",
    "    county_list = None\n",
    "    \n",
    "print county_list\n",
    "\n",
    "# CENSUS API Stuff\n",
    "CENSUS_API = 'fe55211c8b3f0350fcb040c07321a129a3d6e266' # Your key here\n",
    "c = Census(CENSUS_API) # Initialize census class with API key\n",
    "\n",
    "# Generate codes for census variables of interest\n",
    "var_ids = [\"B19001_0{:02d}E\".format(x) for x in range(2, 18)] # Household income over 12 months\n",
    "\n",
    "# TIGER Stuff\n",
    "TIGER_BASE_URL = 'http://www2.census.gov/geo/tiger/TIGER2013/'\n",
    "TIGER_TRACT_DIR = 'TRACT/'\n",
    "TIGER_BLOCKGROUP_DIR = 'BG/'\n",
    "\n",
    "TIGER_WATER_DIR = 'AREAWATER/'\n",
    "\n",
    "tiger_zip_file = 'tl_2013_{0}_tract.zip'.format(state_code)\n",
    "tiger_shape_file = 'tl_2013_{0}_tract.shp'.format(state_code)\n",
    "\n",
    "FULL_TIGER_URL = TIGER_BASE_URL + TIGER_TRACT_DIR + tiger_zip_file\n",
    "\n",
    "# Local Storage Parameters\n",
    "LOCAL_DATA_DIR = './data/'\n",
    "GEO_SUB_DIR = 'geo/'\n",
    "\n",
    "ATTR_FILE_END = '_census_data.csv'\n",
    "attr_outfile = LOCAL_DATA_DIR + loc_name + ATTR_FILE_END\n",
    "\n",
    "GEO_FILE_END = '_geo_data.json'\n",
    "geo_outfile = LOCAL_DATA_DIR + loc_name + GEO_FILE_END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B19001_002E</th>\n",
       "      <th>B19001_003E</th>\n",
       "      <th>B19001_004E</th>\n",
       "      <th>B19001_005E</th>\n",
       "      <th>B19001_006E</th>\n",
       "      <th>B19001_007E</th>\n",
       "      <th>B19001_008E</th>\n",
       "      <th>B19001_009E</th>\n",
       "      <th>B19001_010E</th>\n",
       "      <th>B19001_011E</th>\n",
       "      <th>B19001_012E</th>\n",
       "      <th>B19001_013E</th>\n",
       "      <th>B19001_014E</th>\n",
       "      <th>B19001_015E</th>\n",
       "      <th>B19001_016E</th>\n",
       "      <th>B19001_017E</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>tract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132</td>\n",
       "      <td>84</td>\n",
       "      <td>80</td>\n",
       "      <td>98</td>\n",
       "      <td>93</td>\n",
       "      <td>83</td>\n",
       "      <td>80</td>\n",
       "      <td>99</td>\n",
       "      <td>68</td>\n",
       "      <td>215</td>\n",
       "      <td>165</td>\n",
       "      <td>139</td>\n",
       "      <td>134</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>001</td>\n",
       "      <td>24</td>\n",
       "      <td>000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>92</td>\n",
       "      <td>78</td>\n",
       "      <td>43</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>75</td>\n",
       "      <td>61</td>\n",
       "      <td>24</td>\n",
       "      <td>108</td>\n",
       "      <td>127</td>\n",
       "      <td>141</td>\n",
       "      <td>99</td>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "      <td>17</td>\n",
       "      <td>001</td>\n",
       "      <td>24</td>\n",
       "      <td>000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>164</td>\n",
       "      <td>29</td>\n",
       "      <td>109</td>\n",
       "      <td>42</td>\n",
       "      <td>165</td>\n",
       "      <td>80</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>87</td>\n",
       "      <td>92</td>\n",
       "      <td>113</td>\n",
       "      <td>60</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>001</td>\n",
       "      <td>24</td>\n",
       "      <td>000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87</td>\n",
       "      <td>70</td>\n",
       "      <td>52</td>\n",
       "      <td>32</td>\n",
       "      <td>104</td>\n",
       "      <td>115</td>\n",
       "      <td>120</td>\n",
       "      <td>39</td>\n",
       "      <td>82</td>\n",
       "      <td>77</td>\n",
       "      <td>59</td>\n",
       "      <td>51</td>\n",
       "      <td>149</td>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>001</td>\n",
       "      <td>24</td>\n",
       "      <td>000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>354</td>\n",
       "      <td>134</td>\n",
       "      <td>72</td>\n",
       "      <td>53</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>59</td>\n",
       "      <td>14</td>\n",
       "      <td>38</td>\n",
       "      <td>97</td>\n",
       "      <td>35</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>001</td>\n",
       "      <td>24</td>\n",
       "      <td>000500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  B19001_002E B19001_003E B19001_004E B19001_005E B19001_006E B19001_007E  \\\n",
       "0         132          84          80          98          93          83   \n",
       "1          69          92          78          43          80          80   \n",
       "2          51         164          29         109          42         165   \n",
       "3          87          70          52          32         104         115   \n",
       "4         354         134          72          53          32          50   \n",
       "\n",
       "  B19001_008E B19001_009E B19001_010E B19001_011E B19001_012E B19001_013E  \\\n",
       "0          80          99          68         215         165         139   \n",
       "1          75          61          24         108         127         141   \n",
       "2          80          65          10          87          92         113   \n",
       "3         120          39          82          77          59          51   \n",
       "4          59          14          38          97          35          27   \n",
       "\n",
       "  B19001_014E B19001_015E B19001_016E B19001_017E county state   tract  \n",
       "0         134          17          14           0    001    24  000100  \n",
       "1          99          30          65          17    001    24  000200  \n",
       "2          60          79           0           8    001    24  000300  \n",
       "3         149          51           8          45    001    24  000400  \n",
       "4          26          32          13           0    001    24  000500  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_data = c.acs.get(var_ids, {'for': 'tract:*', 'in': 'state:{0}'.format(state_code)})\n",
    "census_df = pd.DataFrame(census_data)\n",
    "census_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B19001_002E', 'B19001_003E', 'B19001_004E', 'B19001_005E', 'B19001_006E', 'B19001_007E', 'B19001_008E', 'B19001_009E', 'B19001_010E', 'B19001_011E', 'B19001_012E', 'B19001_013E', 'B19001_014E', 'B19001_015E', 'B19001_016E', 'B19001_017E']\n",
      "[u'24', u'10', u'51']\n"
     ]
    }
   ],
   "source": [
    "# This segment of code will get household income estimates for each block group in Baltimore city\n",
    "print var_ids\n",
    "print state_codes\n",
    "census_df = census_tracts_to_dataframe(var_ids, state_codes)\n",
    "census_df.to_csv(attr_outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET TIGER DATA (shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "http://www2.census.gov/geo/tiger/TIGER2013/TRACT/t1_2013_24_tract.zip\n",
      "Try at this link,  http://www2.census.gov/geo/tiger/TIGER2013/TRACT/\n",
      "Not Found\n",
      "Something went wrong. Status code: \n",
      "10\n",
      "http://www2.census.gov/geo/tiger/TIGER2013/TRACT/t1_2013_10_tract.zip\n",
      "Try at this link,  http://www2.census.gov/geo/tiger/TIGER2013/TRACT/\n",
      "Not Found\n",
      "Something went wrong. Status code: \n",
      "51\n",
      "http://www2.census.gov/geo/tiger/TIGER2013/TRACT/t1_2013_51_tract.zip\n",
      "Try at this link,  http://www2.census.gov/geo/tiger/TIGER2013/TRACT/\n",
      "Not Found\n",
      "Something went wrong. Status code: \n"
     ]
    }
   ],
   "source": [
    "for state_id in state_codes:\n",
    "    print state_id\n",
    "    tiger_zip_file = 't1_2013_{0}_tract.zip'.format(state_id)\n",
    "    \n",
    "    FULL_TIGER_URL = TIGER_BASE_URL + TIGER_TRACT_DIR + tiger_zip_file\n",
    "    print FULL_TIGER_URL\n",
    "    # Check if file is in directory, else download it\n",
    "    if os.path.isfile(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_zip_file):\n",
    "        print(\"Already had the file.  Great.\")\n",
    "    else:\n",
    "        r = requests.get(FULL_TIGER_URL)\n",
    "\n",
    "        if r.status_code == requests.codes.ok:\n",
    "            print(\"Got the file! Copying to disk.\")\n",
    "            with open(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_zip_file, \"wb\") as f:\n",
    "                f.write(r.content)\n",
    "        else:\n",
    "            print \"Try at this link, \", TIGER_BASE_URL+TIGER_TRACT_DIR\n",
    "            print r.reason\n",
    "            print(\"Something went wrong. Status code: \".format(r.status_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state_shapes = []\n",
    "for idx, state_id in enumerate(state_codes):\n",
    "    tiger_zip_file = 'tl_2013_{0}_tract.zip'.format(state_id)\n",
    "    tiger_shape_file = 'tl_2013_{0}_tract.shp'.format(state_id)\n",
    "\n",
    "    # Unzip file, extract contents\n",
    "    zfile = zipfile.ZipFile(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_zip_file)\n",
    "    zfile.extractall(LOCAL_DATA_DIR + GEO_SUB_DIR)\n",
    "\n",
    "    # Load to GeoDataFrame\n",
    "    state_shape = gpd.GeoDataFrame.from_file(LOCAL_DATA_DIR + GEO_SUB_DIR + tiger_shape_file)\n",
    "    \n",
    "    state_shapes.append(state_shape)\n",
    "    \n",
    "    # Only keep counties that we are interested in\n",
    "    if county_list is not None:\n",
    "        shapes = shapes[shapes[\"COUNTYFP\"].isin(county_list)]\n",
    "\n",
    "shapes = gpd.GeoDataFrame( pd.concat(state_shapes, ignore_index=True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3531, 13)\n",
      "['510']\n"
     ]
    }
   ],
   "source": [
    "print shapes.shape\n",
    "print county_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminate Unnecessary Attributes -> geojson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small_shapes = gpd.GeoDataFrame()\n",
    "small_shapes[\"geometry\"] = shapes[\"geometry\"].simplify(tolerance=0.001) # Simplify geometry to reduce file size\n",
    "small_shapes[\"fips\"] = shapes[\"GEOID\"]\n",
    "small_shapes = small_shapes.set_index(\"fips\")\n",
    "small_json = small_shapes.to_json()\n",
    "\n",
    "# Write to file\n",
    "with open(geo_outfile, 'w') as f:\n",
    "    f.write(small_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
